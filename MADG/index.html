<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="MADG: Margin-based Adversarial Learning for Domain Generalization">
  <meta name="keywords" content="Domain Generalization, Margin Loss, Adversarial Learning, Domain Adaptation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MADG: Margin-based Adversarial Learning for Domain Generalization</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>

</head>

<body>

  <!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">NeurIPS 2023</h1><br>
            <h1 class="title is-1 publication-title">MADG: Margin-based Adversarial Learning for Domain Generalization</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="">Aveen Dayal</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="">Vimal K B</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="">Linga Reddy Cenkeramaddi</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="">C Krishna Mohan</a><sup>1</sup>,
              </span><br>
              <span class="author-block">
                <a href="">Abhinav Kumar</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="">Vineeth N Balasubramanian</a><sup>1</sup>
              </span>
              <!-- <span class="author-block">
              <a href="">Ricardo Martin-Brualla</a><sup>2</sup>
            </span> -->
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Indian Institute of Technology Hyderabad</span>,
              <span class="author-block"><sup>2</sup>University of Agder</span>,
              <!-- <span class="author-block"><sup>3</sup>University of California, Riverside</span> -->
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2311.08503.pdf" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2311.08503" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/qwedaq/MADG" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/google/nerfies/releases/tag/0.1"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
              </div> -->

              </div>
            </div>
          </div>
        </div>
      </div>
  </section>

  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/teaser.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
          free-viewpoint
          portraits.
        </h2>
      </div>
    </div>
  </section> -->


  <!-- <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/steve.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/chair-tp.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-shiba">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/shiba.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/fullbody.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-blueshirt">
            <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/blueshirt.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-mask">
            <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/mask.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-coffee">
            <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/coffee.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-toby">
            <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/toby2.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section> -->


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>

            </p>
            Domain Generalization (DG) techniques have emerged as a popular approach to
            address the challenges of domain shift in Deep Learning (DL), with the goal of
            generalizing well to the target domain unseen during the training. In recent years,
            numerous methods have been proposed to address the DG setting, among which
            one popular approach is the adversarial learning-based methodology. The main idea
            behind adversarial DG methods is to learn domain-invariant features by minimizing
            a discrepancy metric. However, most adversarial DG methods use 0-1 loss based
            H∆H divergence metric. In contrast, the margin loss-based discrepancy metric
            has the following advantages: more informative, tighter, practical, and efficiently
            optimizable. To mitigate this gap, this work proposes a novel adversarial learning
            DG algorithm, MADG, motivated by a margin loss-based discrepancy metric. The
            proposed MADG model learns domain-invariant features across all source domains
            and uses adversarial training to generalize well to the unseen target domain. We
            also provide a theoretical analysis of the proposed MADG model based on the
            unseen target error bound. Specifically, we construct the link between the source
            and unseen domains in the real-valued hypothesis space and derive the generalization 
            bound using margin loss and Rademacher complexity. We extensively
            experiment with the MADG model on popular real-world DG datasets, VLCS,
            PACS, OfficeHome, DomainNet, and TerraIncognita. We evaluate the proposed
            algorithm on DomainBed’s benchmark and observe consistent performance across
            all the datasets.
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <!-- <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div> -->
      <!--/ Paper video. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Task Objective</h2>
          <!-- <div class="content has-text-centered">
            <p>
              <img src="static\images\MDD1_page-0001.png" alt="Image Description">
            </p><br>
            Figure 1: Space of intersection (agreement) in MDD (yellow) is reduced as compared to 0-1 loss (blue + yellow) between f and f′ for labels {0,1}
          </div> -->
          <div class="content has-text-justified">
            <p>
              Propose an algorithm, a novel margin-based adversarial learning approach for DG, which shows consistent performance over other state-of-the-art methods across benchmarks and derive a generalization bound for an unseen domain based on the margin-based MDD loss in the DG setting.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Method</h2>
          <div class="content has-text-centered">
            <p>
              <img src=".\static\images\MDD1_page-0001.png" alt="Image Description" width="600">
            </p><br>
            Figure 1: Space of intersection (agreement) in MDD (yellow) is reduced as compared to 0-1 loss (blue + yellow) between f and f′ for labels {0,1}
          </div>
          <div class="content has-text-justified">
            <p>
              Derived a generalization bound for an unseen
              domain based on the margin-based MDD loss in the DG
              setting. To this end, we first show an upper bound on the
              unlabeled source domain error given other labeled source
              domains. We then leverage this to develop the upper bound for the error on an unseen domain
              that is not necessarily a source domain. We subsequently analyze the upper bound
              from Corollary 1 using the Rademacher complexity framework and develop our final generalization
              bound for the unseen target domain in the DG setting using our margin-
              based loss.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Results</h2>
          <div class="content has-text-centered">
            <h3 class="subtitle">Image Classification DomainBed</h3>
            <p>
              <img src=".\static\images\MADG_Results.png" alt="Image Description">
            </p>
            <p>
              <!-- Placeholder for Table 3 -->
              Table 1: Accuracy(%) on benchmark DG datasets. Values in red and orange are best and second best-
              performing models in a column, respectively. We report deviation as ±N/A for models that did not report them.
              OH = OfficeHome dataset, TI = TerraIncognita dataset, DN = DomainNet dataset, M = Median rank, AD =
              Arithmetic mean of differences, GD = Geometric mean of differences, Avg. = Average accuracy(%).
            </p>

            <!-- <h3 class="subtitle">Image Classification using self-supervised learning</h3>
            <p>
              <img src="static\images\Table4.png" alt="Image Description">
            </p>
            <p>
              <!-- Table 2: Comparison of different ensemble transferability estimation metrics for self-supervised
              pre-trained models (classification tasks). The best results are indicated in bold. Note: MS: MS-LEEP, E:
              E-LEEP and Ours: OSBORN. -->
            <!-- </p> -->
          </div>
        </div>
      </div>
    </div>
    <!-- <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-centered">
            <br>
            <h3 class="subtitle">t-SNE Plots for Visualization</h3>
            <p>
              <img src="static\images\tSNE_Plots_FSL (1).png" alt="Image Description">
            </p>
            <p>
              t-SNE plots of features learned by corresponding method's ensembles on StanfordCars dataset.
              <i>Optimal</i> chooses best ensemble with exhaustive search
            </p>

          </div>
        </div>
      </div>
    </div> -->
  </section>


  <!-- <section class="section">
    <div class="container is-max-desktop">

      <div class="columns is-centered"> -->


        <!-- Visual Effects. -->
        <!-- <div class="column">
          <div class="content">
            <h2 class="title is-3">Visual Effects</h2>
            <p>
              Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
              would be impossible without nerfies since it would require going through a wall.
            </p>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/dollyzoom-stacked.mp4" type="video/mp4">
            </video>
          </div>
        </div> -->
        <!--/ Visual Effects. -->

        <!-- Matting. -->
        <!-- <div class="column">
          <h2 class="title is-3">Matting</h2>
          <div class="columns is-centered">
            <div class="column content">
              <p>
                As a byproduct of our method, we can also solve the matting problem by ignoring
                samples that fall outside of a bounding box during rendering.
              </p>
              <video id="matting-video" controls playsinline height="100%">
                <source src="./static/videos/matting.mp4" type="video/mp4">
              </video>
            </div>

          </div>
        </div>
      </div> -->
        <!--/ Matting. -->

        <!-- Animation. -->
        <!-- <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Animation</h2>

          
          <h3 class="title is-4">Interpolating states</h3>
          <div class="content has-text-justified">
            <p>
              We can also animate the scene by interpolating the deformation latent codes of two input
              frames. Use the slider here to linearly interpolate between the left frame and the right
              frame.
            </p>
          </div>
          <div class="columns is-vcentered interpolation-panel">
            <div class="column is-3 has-text-centered">
              <img src="./static/images/interpolate_start.jpg" class="interpolation-image"
                alt="Interpolate start reference image." />
              <p>Start Frame</p>
            </div>
            <div class="column interpolation-video-column">
              <div id="interpolation-image-wrapper">
                Loading...
              </div>
              <input class="slider is-fullwidth is-large is-info" id="interpolation-slider" step="1" min="0" max="100"
                value="0" type="range">
            </div>
            <div class="column is-3 has-text-centered">
              <img src="./static/images/interpolate_end.jpg" class="interpolation-image"
                alt="Interpolation end reference image." />
              <p class="is-bold">End Frame</p>
            </div>
          </div>
          <br />
          
          <h3 class="title is-4">Re-rendering the input video</h3>
          <div class="content has-text-justified">
            <p>
              Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
              viewpoint such as a stabilized camera by playing back the training deformations.
            </p>
          </div>
          <div class="content has-text-centered">
            <video id="replay-video" controls muted preload playsinline width="75%">
              <source src="./static/videos/replay.mp4" type="video/mp4">
            </video>
          </div>
         

        </div>
      </div> -->
        <!--/ Animation. -->


        <!-- Concurrent Work. -->
        <!-- <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">Related Links</h2> -->

            <!-- <div class="content has-text-justified">
            <p>
              There's a lot of excellent work that was introduced around the same time as ours.
            </p>
            <p>
              <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an
              idea similar to our windowed position encoding for coarse-to-fine optimization.
            </p>
            <p>
              <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a
                href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
              both use deformation fields to model non-rigid scenes.
            </p>
            <p>
              Some works model videos with a NeRF by directly modulating the density, such as <a
                href="https://video-nerf.github.io/">Video-NeRF</a>, <a
                href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a
                href="https://neural-3d-video.github.io/">DyNeRF</a>
            </p>
            <p>
              There are probably many more by the time you are reading this. Check out <a
                href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a
                href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
            </p>
          </div> -->
          <!-- </div>
        </div> -->
        <!--/ Concurrent Work. -->

      <!-- </div>
  </section> -->


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{osborn,
  author    = {Aveen Dayal, Vimal K. B., Linga Reddy Cenkeramaddi, C. Krishna Mohan, Abhinav Kumar, Vineeth N Balasubramanian},
  title     = {MADG: Margin-based Adversarial Learning for Domain Generalization},
  journal   = {NeurIPS},
  year      = {2023},
}</code></pre>
    </div>
  </section>
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">Contact Us</h2>
      Please contact us any of the following email IDs for further information regarding our paper
      <pre><code>
        ai21resch11003@iith.ac.in, 
        vimalkb96@gmail.com, 
        vineethnb@cse.iith.ac.in
      </code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/qwedaq/MADG" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              The source code for this website can be viewed <a href="https://github.com/vimalkb007/MADG">here</a>.
            </p>
            <p>
              The source code for the website is borrowed from this <a href="https://github.com/nerfies/nerfies.github.io">repository</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
